name: spark
summary: Spark ROCK
description: Spark ROCK
license: Apache-2.0

version: "3.3.1"
base: ubuntu:22.04
platforms:
  amd64:

entrypoint: ["/bin/bash", "/opt/pebble-start.sh"]

env:
  - SPARK_HOME: /opt/spark
  - JAVA_HOME: /usr/lib/jvm/java-11-openjdk-amd64
  - PYTHONPATH: /opt/spark/python:/opt/spark/python/build:/opt/spark/bin:$SNAP/usr/lib/python3/dist-packages:/opt/spark/python/dist:$PYTHONPATH
  - PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/spark:/opt/spark/bin
  - HOME: /opt/spark

parts:

  spark:
    plugin: dump
    source: https://downloads.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz
    source-checksum: sha512/769db39a560a95fd88b58ed3e9e7d1e92fb68ee406689fb4d30c033cb5911e05c1942dcc70e5ec4585df84e80aabbc272b9386a208debda89522efff1335c8ff
    overlay-script: |
      set -ex
      sed -i 's/http:\/\/deb.\(.*\)/https:\/\/deb.\1/g' /etc/apt/sources.list
      apt-get update
      ln -svf /lib /lib64
      # apt-get install -y bash tini libc6 libpam-modules krb5-user libnss3 procps
      apt-get install -y bash
      mkdir -p /opt/spark/python
      touch /opt/spark/RELEASE
      rm /bin/sh
      ln -svf /bin/bash /bin/sh
      echo "auth required pam_wheel.so use_uid" >> /etc/pam.d/su
      # chgrp root /etc/passwd && chmod ug+rw /etc/passwd
      rm -rf /var/cache/apt/*
    organize:
      conf: opt/spark/conf
      jars: opt/spark/jars
      bin: opt/spark/bin
      sbin: opt/spark/sbin
      python: opt/spark/python
      kubernetes/dockerfiles/spark/entrypoint.sh: opt/entrypoint.sh
      kubernetes/dockerfiles/spark/decom.sh: opt/decom.sh
      examples: opt/spark/examples
      kubernetes/tests: opt/spark/tests
      data: opt/spark/data
    stage:
       - opt/spark/conf
       - opt/spark/jars
       - opt/spark/bin
       - opt/spark/sbin
       - opt/entrypoint.sh
       - opt/decom.sh
       - opt/spark/examples
       - opt/spark/tests
       - opt/spark/data
       - opt/spark/python

  hadoop-jars:
    plugin: nil
    after: [spark]
    build-packages:
      - wget
    overlay-script: |
      AWS_JAVA_SDK_BUNDLE_VERSION='1.11.874'
      HADOOP_AWS_VERSION='3.2.2'
      mkdir -p $CRAFT_PART_INSTALL/opt/spark/jars
      cd $CRAFT_PART_INSTALL/opt/spark/jars
      wget -q "https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/${AWS_JAVA_SDK_BUNDLE_VERSION}/aws-java-sdk-bundle-${AWS_JAVA_SDK_BUNDLE_VERSION}.jar"
      wget -q "https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/${AWS_JAVA_SDK_BUNDLE_VERSION}/aws-java-sdk-bundle-${AWS_JAVA_SDK_BUNDLE_VERSION}.jar.sha1"  
      echo "`cat aws-java-sdk-bundle-${AWS_JAVA_SDK_BUNDLE_VERSION}.jar.sha1`  aws-java-sdk-bundle-${AWS_JAVA_SDK_BUNDLE_VERSION}.jar" | sha1sum --check
      if  [[ $? -ne 0 ]]
        then
          echo "DOWNLOAD ERROR: aws-java-sdk-bundle-${AWS_JAVA_SDK_BUNDLE_VERSION}.jar could not be downloaded properly! Exiting...."
          exit 1
      fi
      wget -q "https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/${HADOOP_AWS_VERSION}/hadoop-aws-${HADOOP_AWS_VERSION}.jar"
      wget -q "https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/${HADOOP_AWS_VERSION}/hadoop-aws-${HADOOP_AWS_VERSION}.jar.sha1"
      echo "`cat hadoop-aws-${HADOOP_AWS_VERSION}.jar.sha1`  hadoop-aws-${HADOOP_AWS_VERSION}.jar" | sha1sum --check
      if  [[ $? -ne 0 ]]
        then
          echo "DOWNLOAD ERROR: hadoop-aws-${HADOOP_AWS_VERSION}.jar could not be downloaded properly! Exiting...."
          exit 1
      fi
    stage:
      - opt/spark/jars

  client-scripts:
    plugin: nil
    after: [hadoop-jars]
    build-packages:
      - wget
    overlay-packages:
      - python3-pip
    overlay-script: |
      SPARK_CLIENT_PKG_VERSION='0.0.2'
      mkdir -p $CRAFT_PART_INSTALL/opt/spark/python/dist
      cd $CRAFT_PART_INSTALL/opt/spark/python/dist
      echo "Downloading latest available Spark wheel package release v${SPARK_CLIENT_PKG_VERSION}."
      wget https://github.com/canonical/spark-client-snap/releases/download/v${SPARK_CLIENT_PKG_VERSION}/spark_client-${SPARK_CLIENT_PKG_VERSION}-py3-none-any.whl --no-check-certificate
      if  [[ $? -ne 0 ]]
        then
          echo "DOWNLOAD ERROR: Spark client package v${SPARK_CLIENT_PKG_VERSION} could not be downloaded properly! Exiting...."
          exit 1
      fi
      pip install --target=${CRAFT_PART_INSTALL}/opt/spark/python/dist ./spark_client-${SPARK_CLIENT_PKG_VERSION}-py3-none-any.whl
    stage:
      - opt/spark/python/dist

  kubectl-bin:
    plugin: nil
    after: [client-scripts]
    build-packages:
      - curl
    overlay-script: |
      mkdir -p $CRAFT_PART_INSTALL/opt/spark
      cd $CRAFT_PART_INSTALL/opt/spark
      curl -LO -s "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
      curl -LO "https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256"
      echo "$(cat kubectl.sha256)  kubectl" | sha256sum --check
      if  [[ $? -ne 0 ]]
        then
          echo "DOWNLOAD ERROR: kubectl could not be downloaded properly! Exiting...."
          exit 1
      fi
      chmod +x kubectl
    stage:
      - opt/spark

  user-setup:
    plugin: nil
    after: [kubectl-bin]
    overlay-packages:
      - tini
      - libc6
      - libpam-modules
      - krb5-user
      - libnss3
      - procps
      - openjdk-11-jre-headless
      - python3-setuptools
    overlay-script: |
      SPARK_GID=185
      SPARK_UID=185
      
      # Create a user in the $CRAFT_OVERLAY chroot
      groupadd -R $CRAFT_OVERLAY -g ${SPARK_GID} spark
      useradd -R $CRAFT_OVERLAY -M -r -g spark -u ${SPARK_UID} spark
    override-prime: |  
      SPARK_GID=185
      SPARK_UID=185
      
      craftctl default
      chown -R ${SPARK_GID}:${SPARK_UID} opt/spark
      chmod -R 770 opt/spark
      
      chown ${SPARK_GID}:${SPARK_UID} opt/entrypoint.sh
      chmod 770 opt/entrypoint.sh
      
      chown ${SPARK_GID}:${SPARK_UID} opt/decom.sh
      chmod 770 opt/decom.sh

  pebble-setup:
    plugin: dump
    source: files
    organize:
      pebble-start.sh: opt/pebble-start.sh
    overlay-script:
      mkdir -p $CRAFT_PART_INSTALL/var/lib/pebble/default
    stage:
      - opt/pebble-start.sh
      - var/lib/pebble/default

